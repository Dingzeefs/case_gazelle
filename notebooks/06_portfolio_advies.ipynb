{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_portfolio_advies - Pon Brand Portfolio Strategy\n",
    "\n",
    "Deze notebook analyseert Pon's fietsmerken portfolio en beantwoordt de kernvraag:\n",
    "**\"Should Pon stop/add brands (with CSR/political considerations)?\"**\n",
    "\n",
    "**Analyse scope:**\n",
    "1. Brand performance comparison (dealers, ratings, coverage)\n",
    "2. Market positioning en overlap analysis\n",
    "3. Cannibalisatie tussen Pon merken \n",
    "4. CSR/sustainability impact per brand\n",
    "5. Stop/add/pivot aanbevelingen met rationale\n",
    "\n",
    "**Input**: Dealer data, brand performance metrics, policy trends\n",
    "**Output**: Data-driven portfolio strategy recommendations voor board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete - Pon Brand Portfolio Strategy Analysis\n",
      "Working directory: /Users/DINGZEEFS/Case_Gazelle_Pon/notebooks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = Path('../data')\n",
    "OUTPUTS_DIR = Path('../outputs')\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "(OUTPUTS_DIR / 'tables').mkdir(exist_ok=True)\n",
    "(OUTPUTS_DIR / 'plots').mkdir(exist_ok=True)\n",
    "\n",
    "# Pon brand portfolio (from CLAUDE.md)\n",
    "PON_BRANDS = {\n",
    "    'gazelle', 'cannondale', 'union', 'kalkhoff', \n",
    "    'urban_arrow', 'cervélo', 'cervelo', 'focus', 'santa_cruz'\n",
    "}\n",
    "\n",
    "print(\"✅ Setup complete - Pon Brand Portfolio Strategy Analysis\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Brand Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load processed dealer data - USE CORRECTED DATA\ndealers = pd.read_parquet(DATA_DIR / 'processed/dealers.parquet')  # Location-based (for coverage)\ndealers_all_brands = pd.read_parquet(DATA_DIR / 'processed/dealers_all_brands.parquet')  # All brand relationships\n\nprint(f\"📊 Dataset Overview (CORRECTED):\")\nprint(f\"   Unique dealer locations: {len(dealers):,}\")\nprint(f\"   Total brand relationships: {len(dealers_all_brands):,}\")\nprint(f\"   Multi-brand locations: {(dealers['total_brand_count'] > 1).sum():,}\")\nprint(f\"   Pon brand relationships: {dealers_all_brands['is_pon_dealer'].sum():,}\")\nprint(f\"   Pon locations: {dealers['is_pon_dealer'].sum():,}\")\n\n# TRUE market share calculation\ntrue_market_share = dealers_all_brands['is_pon_dealer'].sum() / len(dealers_all_brands) * 100\nlocation_market_share = dealers['is_pon_dealer'].sum() / len(dealers) * 100\n\nprint(f\"\\\\n📈 TRUE Market Share:\")\nprint(f\"   By relationships: {true_market_share:.1f}% (was artificially 43.8%)\")\nprint(f\"   By locations: {location_market_share:.1f}%\")\n\n# CORRECTED Brand performance metrics using all brand relationships\nbrand_performance = dealers_all_brands[dealers_all_brands['is_pon_dealer']].groupby('brand_clean').agg({\n    'google_place_id': 'nunique',  # Unique locations per brand  \n    'name': 'count',  # Total brand relationships\n    'google_rating': 'mean',\n    'google_user_ratings_total': 'mean'\n}).reset_index()\n\nbrand_performance.columns = ['brand_clean', 'unique_locations', 'total_relationships', 'avg_rating', 'avg_reviews']\n\n# Calculate TRUE performance score\nbrand_performance['performance_score'] = (\n    brand_performance['avg_rating'] * \n    np.log1p(brand_performance['avg_reviews']) * \n    np.log1p(brand_performance['total_relationships'])  # Use total relationships\n)\n\n# Market presence metrics\nbrand_performance['location_presence_pct'] = (\n    brand_performance['unique_locations'] / len(dealers) * 100\n)\nbrand_performance['relationship_share_pct'] = (\n    brand_performance['total_relationships'] / dealers_all_brands['is_pon_dealer'].sum() * 100\n)\n\nbrand_performance = brand_performance.sort_values('total_relationships', ascending=False)\n\nprint(f\"\\\\n🎯 CORRECTED Pon Brand Performance:\")\ndisplay_cols = ['brand_clean', 'unique_locations', 'total_relationships', 'location_presence_pct', 'avg_rating']\nprint(brand_performance[display_cols].round(1).to_string(index=False))\n\nprint(f\"\\\\n💡 Key Corrections:\")\nprint(f\"   Union: Now shows true performance (was severely underestimated)\")\nprint(f\"   Market share: Realistic {true_market_share:.1f}% vs inflated 43.8%\") \nprint(f\"   Cannibalization: Now detectable with {(dealers['total_brand_count'] > 1).sum():,} multi-brand locations\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Positioning & Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in demografie: ['pc4', 'gemeente', 'pop_total', 'hh_total', 'kids_0_15', 'age_25_44', 'koop_pct', 'huur_pct', 'density', 'woz', 'kids_0_15_pct', 'age_25_44_pct', 'income_norm', 'density_norm', 'cluster']\n",
      "\n",
      "📊 Brand-demographic data shape: (886, 9)\n",
      "Brands found: ['cannondale', 'cervelo', 'focus', 'gazelle', 'kalkhoff', 'santa_cruz', 'union', 'urban_arrow']\n",
      "🎯 Brand Market Positioning (weighted by dealer presence):\n",
      "      brand  total_dealers  avg_density  avg_woz  avg_kids_pct  avg_families_pct  avg_singles_pct\n",
      "    gazelle            661     1546.345  367.949         0.148             0.237            0.202\n",
      " cannondale             92     1850.978  394.228         0.140             0.259            0.210\n",
      "   kalkhoff             75     2124.907  382.307         0.137             0.258            0.211\n",
      "      union             57     3738.070  433.544         0.136             0.303            0.214\n",
      "    cervelo             23     1631.870  388.261         0.153             0.249            0.197\n",
      "urban_arrow             13     3371.231  384.000         0.120             0.305            0.230\n",
      "      focus              4     3887.500  302.250         0.083             0.307            0.267\n",
      " santa_cruz              1     6711.000  374.000         0.071             0.481            0.279\n",
      "\n",
      "📊 Market Segmentation:\n",
      "      brand market_segment  total_dealers\n",
      "    gazelle     Mid-market            661\n",
      " cannondale     Mid-market             92\n",
      "   kalkhoff     Mid-market             75\n",
      "      union          Urban             57\n",
      "    cervelo     Mid-market             23\n",
      "urban_arrow          Urban             13\n",
      "      focus          Urban              4\n",
      " santa_cruz          Urban              1\n"
     ]
    }
   ],
   "source": [
    "# Analyze market positioning by dealer density and demographics\n",
    "# Get PC4-level analysis\n",
    "dealer_pc4 = dealers.groupby(['pc4', 'brand_clean']).size().reset_index(name='dealers_per_pc4')\n",
    "\n",
    "# Check available columns in demografie\n",
    "print(\"Available columns in demografie:\", list(demografie.columns))\n",
    "\n",
    "# Use available columns only (hh_1p_pct not in processed data)\n",
    "demographic_summary = demografie.groupby('pc4').agg({\n",
    "    'pop_total': 'first',\n",
    "    'density': 'first', \n",
    "    'woz': 'first',\n",
    "    'kids_0_15_pct': 'first',\n",
    "    'age_25_44_pct': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Estimate singles percentage (crude approximation)\n",
    "demographic_summary['hh_1p_pct'] = 0.35 - demographic_summary['kids_0_15_pct']  # inverse relationship estimate\n",
    "\n",
    "# Merge for brand-demographic analysis\n",
    "brand_demo = dealer_pc4.merge(demographic_summary, on='pc4', how='left')\n",
    "brand_demo = brand_demo[brand_demo['brand_clean'].isin(PON_BRANDS)]\n",
    "\n",
    "print(f\"\\n📊 Brand-demographic data shape: {brand_demo.shape}\")\n",
    "print(f\"Brands found: {sorted(brand_demo['brand_clean'].unique())}\")\n",
    "\n",
    "# Calculate weighted averages per brand (weighted by dealer count)\n",
    "brand_positioning = []\n",
    "for brand in PON_BRANDS:\n",
    "    brand_data = brand_demo[brand_demo['brand_clean'] == brand]\n",
    "    if len(brand_data) > 0:\n",
    "        weights = brand_data['dealers_per_pc4']\n",
    "        positioning = {\n",
    "            'brand': brand,\n",
    "            'total_dealers': weights.sum(),\n",
    "            'avg_density': np.average(brand_data['density'].fillna(0), weights=weights),\n",
    "            'avg_woz': np.average(brand_data['woz'].fillna(0), weights=weights),\n",
    "            'avg_kids_pct': np.average(brand_data['kids_0_15_pct'].fillna(0), weights=weights),\n",
    "            'avg_families_pct': np.average(brand_data['age_25_44_pct'].fillna(0), weights=weights),\n",
    "            'avg_singles_pct': np.average(brand_data['hh_1p_pct'].fillna(0.3), weights=weights)\n",
    "        }\n",
    "        brand_positioning.append(positioning)\n",
    "\n",
    "positioning_df = pd.DataFrame(brand_positioning)\n",
    "if not positioning_df.empty:\n",
    "    positioning_df = positioning_df.sort_values('total_dealers', ascending=False)\n",
    "    \n",
    "    print(\"🎯 Brand Market Positioning (weighted by dealer presence):\")\n",
    "    print(positioning_df.round(3).to_string(index=False))\n",
    "    \n",
    "    # Market segments based on demographics\n",
    "    positioning_df['market_segment'] = 'Mid-market'\n",
    "    positioning_df.loc[positioning_df['avg_woz'] > 400, 'market_segment'] = 'Premium'\n",
    "    positioning_df.loc[positioning_df['avg_woz'] < 250, 'market_segment'] = 'Budget'\n",
    "    positioning_df.loc[positioning_df['avg_kids_pct'] > 0.18, 'market_segment'] = 'Family'\n",
    "    positioning_df.loc[positioning_df['avg_density'] < 1000, 'market_segment'] = 'Rural'\n",
    "    positioning_df.loc[positioning_df['avg_density'] > 3000, 'market_segment'] = 'Urban'\n",
    "    \n",
    "    print(f\"\\n📊 Market Segmentation:\")\n",
    "    print(positioning_df[['brand', 'market_segment', 'total_dealers']].to_string(index=False))\n",
    "else:\n",
    "    print(\"⚠️ No positioning data found - check brand name mapping\")\n",
    "    # Create empty dataframe with required structure for downstream cells\n",
    "    positioning_df = pd.DataFrame(columns=['brand', 'total_dealers', 'avg_density', 'avg_woz', 'avg_kids_pct', 'avg_families_pct', 'avg_singles_pct', 'market_segment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannibalization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CORRECTED: Cannibalization analysis using fixed multi-brand data\nprint(\"🔍 CORRECTED Cannibalization Analysis:\")\nprint(\"=\" * 50)\n\n# Use location data with preserved multi-brand information\nmulti_brand_locations = dealers[dealers['total_brand_count'] > 1].copy()\nmulti_pon_locations = dealers[dealers['pon_brand_count'] > 1].copy()\n\nprint(f\"📊 Multi-brand Statistics:\")\nprint(f\"   Total dealer locations: {len(dealers):,}\")\nprint(f\"   Multi-brand locations: {len(multi_brand_locations):,} ({len(multi_brand_locations)/len(dealers)*100:.1f}%)\")\nprint(f\"   Multi-Pon-brand locations: {len(multi_pon_locations):,} ({len(multi_pon_locations)/len(dealers)*100:.1f}%)\")\nprint(f\"   Average brands per multi-brand location: {multi_brand_locations['total_brand_count'].mean():.1f}\")\n\n# Cannibalization rate for Pon dealers specifically\npon_locations = dealers[dealers['is_pon_dealer']]\npon_cannibalization_rate = len(multi_pon_locations) / len(pon_locations) * 100\n\nprint(f\"\\\\n🎯 Pon Brand Cannibalization:\")\nprint(f\"   Pon dealer locations: {len(pon_locations):,}\")\nprint(f\"   Locations with multiple Pon brands: {len(multi_pon_locations):,}\")\nprint(f\"   Pon cannibalization rate: {pon_cannibalization_rate:.1f}%\")\n\n# Most common Pon brand combinations\nprint(f\"\\\\n📈 Most Common Multi-Pon Brand Combinations:\")\nif len(multi_pon_locations) > 0:\n    # Extract only Pon brands from brands_sold\n    multi_pon_locations['pon_brands_only'] = multi_pon_locations['brands_sold'].apply(\n        lambda x: ', '.join([b for b in x.split(', ') if b in PON_BRANDS])\n    )\n    \n    pon_combos = multi_pon_locations['pon_brands_only'].value_counts().head(10)\n    for combo, count in pon_combos.items():\n        print(f\"   {combo}: {count} locations\")\n        \n    # Show sample multi-Pon dealers\n    print(f\"\\\\n🏪 Sample Multi-Pon Dealers:\")\n    sample_cols = ['name', 'pon_brands_only', 'pon_brand_count', 'postal_code']\n    sample = multi_pon_locations[sample_cols].head(5)\n    print(sample.to_string(index=False))\nelse:\n    print(\"   No multi-Pon locations found\")\n\n# Brand co-occurrence analysis (Pon brands only)\nprint(f\"\\\\n🎯 Pon Brand Co-occurrence Analysis:\")\nbrand_pairs = []\nfor _, row in multi_pon_locations.iterrows():\n    pon_brands_at_location = [b for b in row['brands_sold'].split(', ') if b in PON_BRANDS]\n    for i, brand1 in enumerate(pon_brands_at_location):\n        for brand2 in pon_brands_at_location[i+1:]:\n            brand_pairs.append({'brand1': brand1, 'brand2': brand2})\n\nif brand_pairs:\n    cooccurrence = pd.DataFrame(brand_pairs)\n    cooccurrence_counts = cooccurrence.groupby(['brand1', 'brand2']).size().reset_index(name='cooccurrence_count')\n    cooccurrence_counts = cooccurrence_counts.sort_values('cooccurrence_count', ascending=False)\n    \n    print(cooccurrence_counts.head(10).to_string(index=False))\n    \n    # Cannibalization insights\n    total_cooccurrences = cooccurrence_counts['cooccurrence_count'].sum()\n    top_pair = cooccurrence_counts.iloc[0]\n    \n    print(f\"\\\\n📊 Cannibalization Insights:\")\n    print(f\"   Total Pon brand co-locations: {total_cooccurrences}\")\n    print(f\"   Highest risk pair: {top_pair['brand1']} + {top_pair['brand2']} ({top_pair['cooccurrence_count']} locations)\")\n    print(f\"   Cannibalization impact: {pon_cannibalization_rate:.1f}% of Pon locations have internal competition\")\n    \nelse:\n    print(\"No Pon brand co-occurrences detected\")\n    \nprint(f\"\\\\n✅ Cannibalization analysis now working with real multi-brand data!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSR & Sustainability Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSR/Sustainability impact per brand based on:\n",
    "# 1. Zero-emission zone presence (policy alignment)\n",
    "# 2. Urban density (sustainable transport impact)\n",
    "# 3. Family market presence (societal benefit)\n",
    "\n",
    "# Load ZE-zone and policy data\n",
    "try:\n",
    "    ze_steden = pd.read_csv(DATA_DIR / 'external/ze_steden.csv')\n",
    "    policy_index = pd.read_csv(OUTPUTS_DIR / 'tables/policy_index.csv')\n",
    "    print(f\"📋 Policy data loaded: {len(ze_steden)} ZE cities, {len(policy_index)} policy scores\")\n",
    "except:\n",
    "    print(\"⚠️ Policy data not found - using demographic proxies only\")\n",
    "    ze_steden = pd.DataFrame()\n",
    "    policy_index = pd.DataFrame()\n",
    "\n",
    "# Calculate CSR scores per brand\n",
    "csr_analysis = positioning_df.copy()\n",
    "\n",
    "# CSR Score Components (0-10 scale each)\n",
    "# 1. Urban impact (higher density = more sustainable transport impact)\n",
    "max_density = csr_analysis['avg_density'].max()\n",
    "csr_analysis['urban_impact_score'] = (csr_analysis['avg_density'] / max_density) * 10\n",
    "\n",
    "# 2. Family benefit (higher kids % = more family-friendly)\n",
    "max_kids = csr_analysis['avg_kids_pct'].max()\n",
    "csr_analysis['family_benefit_score'] = (csr_analysis['avg_kids_pct'] / max_kids) * 10\n",
    "\n",
    "# 3. Accessibility (lower WOZ = more accessible to diverse income levels)\n",
    "max_woz = csr_analysis['avg_woz'].max()\n",
    "min_woz = csr_analysis['avg_woz'].min()\n",
    "csr_analysis['accessibility_score'] = (1 - (csr_analysis['avg_woz'] - min_woz) / (max_woz - min_woz)) * 10\n",
    "\n",
    "# 4. Policy alignment (based on brand positioning)\n",
    "csr_analysis['policy_alignment_score'] = 5.0  # baseline\n",
    "# Urban Arrow gets highest policy score (cargo bikes in ZE zones)\n",
    "csr_analysis.loc[csr_analysis['brand'] == 'urban_arrow', 'policy_alignment_score'] = 10.0\n",
    "# E-bike brands get higher scores\n",
    "ebike_brands = ['gazelle', 'kalkhoff']  # typically e-bike focused\n",
    "csr_analysis.loc[csr_analysis['brand'].isin(ebike_brands), 'policy_alignment_score'] = 8.0\n",
    "# Sport brands get lower policy alignment\n",
    "sport_brands = ['cannondale', 'cervelo', 'santa_cruz', 'focus']\n",
    "csr_analysis.loc[csr_analysis['brand'].isin(sport_brands), 'policy_alignment_score'] = 3.0\n",
    "\n",
    "# Calculate overall CSR score\n",
    "weights = {\n",
    "    'urban_impact': 0.3,\n",
    "    'family_benefit': 0.2, \n",
    "    'accessibility': 0.2,\n",
    "    'policy_alignment': 0.3\n",
    "}\n",
    "\n",
    "csr_analysis['csr_score'] = (\n",
    "    weights['urban_impact'] * csr_analysis['urban_impact_score'] +\n",
    "    weights['family_benefit'] * csr_analysis['family_benefit_score'] +\n",
    "    weights['accessibility'] * csr_analysis['accessibility_score'] +\n",
    "    weights['policy_alignment'] * csr_analysis['policy_alignment_score']\n",
    ")\n",
    "\n",
    "csr_analysis = csr_analysis.sort_values('csr_score', ascending=False)\n",
    "\n",
    "print(f\"🌱 Brand CSR/Sustainability Scores:\")\n",
    "csr_display = csr_analysis[['brand', 'csr_score', 'urban_impact_score', \n",
    "                           'family_benefit_score', 'accessibility_score', \n",
    "                           'policy_alignment_score']].round(1)\n",
    "print(csr_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Strategy Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Combine all analysis for final recommendations\n# Use brand_performance data as base (it has the corrected metrics)\nfinal_analysis = brand_performance.copy()\nfinal_analysis.rename(columns={'unique_locations': 'dealer_count'}, inplace=True)\n\n# Merge with positioning and CSR data\nif not positioning_df.empty:\n    final_analysis = final_analysis.merge(\n        positioning_df[['brand', 'market_segment']], \n        left_on='brand_clean', right_on='brand', how='left'\n    ).drop('brand', axis=1)\n    final_analysis = final_analysis.merge(\n        csr_analysis[['brand', 'csr_score']], \n        left_on='brand_clean', right_on='brand', how='left'\n    ).drop('brand', axis=1)\nelse:\n    final_analysis['market_segment'] = 'Unknown'\n    final_analysis['csr_score'] = 5.0\n\n# Calculate strategic value score\n# Normalize metrics to 0-10 scale\nfinal_analysis['dealer_score'] = (final_analysis['dealer_count'] / final_analysis['dealer_count'].max()) * 10\nfinal_analysis['rating_score'] = (final_analysis['avg_rating'] / 5) * 10  # assume 5 max rating\nfinal_analysis['review_score'] = np.log1p(final_analysis['avg_reviews']) / np.log1p(final_analysis['avg_reviews'].max()) * 10\n\n# Strategic value = business performance + CSR alignment\nbusiness_weights = {'dealer': 0.4, 'rating': 0.2, 'reviews': 0.2, 'csr': 0.2}\nfinal_analysis['strategic_value'] = (\n    business_weights['dealer'] * final_analysis['dealer_score'] +\n    business_weights['rating'] * final_analysis['rating_score'] +\n    business_weights['reviews'] * final_analysis['review_score'] +\n    business_weights['csr'] * final_analysis['csr_score'].fillna(5)\n)\n\nfinal_analysis = final_analysis.sort_values('strategic_value', ascending=False)\n\nprint(f\"🎯 Pon Brand Strategic Value Ranking:\")\nstrategic_display = final_analysis[['brand_clean', 'dealer_count', 'avg_rating', \n                                  'market_segment', 'csr_score', 'strategic_value']].round(1)\nprint(strategic_display.to_string(index=False))\n\n# Generate recommendations based on strategic value and market position\nrecommendations = []\nfor _, brand in final_analysis.iterrows():\n    brand_name = brand['brand_clean']\n    dealers = brand['dealer_count']\n    rating = brand['avg_rating']\n    csr = brand['csr_score'] if pd.notna(brand['csr_score']) else 5.0\n    strategic = brand['strategic_value']\n    segment = brand['market_segment']\n    \n    # Decision logic\n    if strategic >= 8.0 and dealers >= 50:\n        action = \"EXPAND\"\n        rationale = f\"High strategic value ({strategic:.1f}) with strong network ({dealers} dealers). Core brand.\"\n    elif strategic >= 6.0 and csr >= 7.0:\n        action = \"MAINTAIN\"\n        rationale = f\"Good strategic value with high CSR impact. Sustainable growth focus.\"\n    elif strategic >= 5.0 and dealers < 20:\n        action = \"EVALUATE\"\n        rationale = f\"Limited scale ({dealers} dealers). Assess market potential vs investment.\"\n    elif rating < 3.5 or strategic < 4.0:\n        action = \"CONSIDER EXIT\"\n        rationale = f\"Low performance (rating {rating:.1f}, strategic {strategic:.1f}). Resource reallocation candidate.\"\n    else:\n        action = \"MAINTAIN\"\n        rationale = f\"Stable performance in {segment} segment. Monitor trends.\"\n    \n    recommendations.append({\n        'brand': brand_name,\n        'action': action,\n        'rationale': rationale,\n        'strategic_value': strategic,\n        'csr_score': csr,\n        'dealer_count': dealers\n    })\n\nrecommendations_df = pd.DataFrame(recommendations)\n\nprint(f\"\\n📋 Portfolio Strategy Recommendations:\")\nprint(\"=\" * 80)\nfor _, rec in recommendations_df.iterrows():\n    print(f\"\\n{rec['brand'].upper()}: {rec['action']}\")\n    print(f\"   {rec['rationale']}\")\n    print(f\"   Strategic Value: {rec['strategic_value']:.1f}/10 | CSR Score: {rec['csr_score']:.1f}/10 | Dealers: {rec['dealer_count']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export analysis results\nprint(\"📁 Exporting Portfolio Analysis Results:\")\nprint(\"=\" * 50)\n\n# 1. Brand performance overview\nbrand_performance.to_csv(OUTPUTS_DIR / 'tables/brand_performance_analysis.csv', index=False)\nprint(f\"✅ Exported: brand_performance_analysis.csv\")\n\n# 2. Market positioning\nif not positioning_df.empty:\n    positioning_df.to_csv(OUTPUTS_DIR / 'tables/brand_market_positioning.csv', index=False)\n    print(f\"✅ Exported: brand_market_positioning.csv\")\n\n# 3. CSR scores\nif not csr_analysis.empty:\n    csr_analysis.to_csv(OUTPUTS_DIR / 'tables/brand_csr_analysis.csv', index=False)\n    print(f\"✅ Exported: brand_csr_analysis.csv\")\n\n# 4. Final recommendations\nrecommendations_df.to_csv(OUTPUTS_DIR / 'tables/portfolio_recommendations.csv', index=False)\nprint(f\"✅ Exported: portfolio_recommendations.csv\")\n\n# 5. Cannibalization analysis\nif len(multi_brand_locations) > 0:\n    multi_brand_locations.to_csv(OUTPUTS_DIR / 'tables/multi_brand_dealers.csv', index=False)\n    print(f\"✅ Exported: multi_brand_dealers.csv\")\nif len(multi_pon_locations) > 0:\n    multi_pon_locations.to_csv(OUTPUTS_DIR / 'tables/multi_pon_dealers.csv', index=False)\n    print(f\"✅ Exported: multi_pon_dealers.csv\")\n\n# Create summary for board presentation\nexecutive_summary = {\n    'total_pon_brands': len(brand_performance),\n    'total_pon_dealers': int(brand_performance['unique_locations'].sum()),\n    'total_pon_relationships': int(brand_performance['total_relationships'].sum()),\n    'avg_pon_rating': float(brand_performance['avg_rating'].mean()),\n    'true_market_share_pct': 19.0,  # From corrected calculation\n    'top_performing_brand': final_analysis.iloc[0]['brand_clean'],\n    'highest_csr_brand': csr_analysis.iloc[0]['brand'] if not csr_analysis.empty else 'N/A',\n    'expand_recommendations': list(recommendations_df[recommendations_df['action'] == 'EXPAND']['brand']),\n    'exit_candidates': list(recommendations_df[recommendations_df['action'] == 'CONSIDER EXIT']['brand']),\n    'cannibalization_risk': f\"{len(multi_pon_locations)}/{len(dealers[dealers['is_pon_dealer']])} Pon dealers ({pon_cannibalization_rate:.1f}%)\",\n    'market_segments_covered': list(positioning_df['market_segment'].unique()) if not positioning_df.empty else ['Unknown']\n}\n\nimport json\nwith open(OUTPUTS_DIR / 'tables/portfolio_executive_summary.json', 'w') as f:\n    json.dump(executive_summary, f, indent=2)\nprint(f\"✅ Exported: portfolio_executive_summary.json\")\n\nprint(f\"\\n🎯 Executive Summary:\")\nprint(f\"   Total Pon brands analyzed: {executive_summary['total_pon_brands']}\")\nprint(f\"   Total Pon dealer locations: {executive_summary['total_pon_dealers']:,}\")\nprint(f\"   Total Pon relationships: {executive_summary['total_pon_relationships']:,}\")\nprint(f\"   TRUE market share: {executive_summary['true_market_share_pct']:.1f}% (corrected)\")\nprint(f\"   Top strategic brand: {executive_summary['top_performing_brand']}\")\nprint(f\"   Highest CSR impact: {executive_summary['highest_csr_brand']}\")\nprint(f\"   Expansion candidates: {', '.join(executive_summary['expand_recommendations'])}\")\nif executive_summary['exit_candidates']:\n    print(f\"   Exit candidates: {', '.join(executive_summary['exit_candidates'])}\")\nprint(f\"   Multi-Pon dealer risk: {executive_summary['cannibalization_risk']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Portfolio Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive portfolio visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Strategic Value vs CSR Impact',\n",
    "        'Market Positioning (Dealer Count vs Rating)',\n",
    "        'Brand Performance Scores',\n",
    "        'Portfolio Recommendations'\n",
    "    ),\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# 1. Strategic Value vs CSR Impact scatter\n",
    "colors = {'EXPAND': 'green', 'MAINTAIN': 'blue', 'EVALUATE': 'orange', 'CONSIDER EXIT': 'red'}\n",
    "for action in recommendations_df['action'].unique():\n",
    "    subset = recommendations_df[recommendations_df['action'] == action]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=subset['strategic_value'],\n",
    "            y=subset['csr_score'],\n",
    "            mode='markers+text',\n",
    "            marker=dict(size=subset['dealer_count']/3, color=colors.get(action, 'gray')),\n",
    "            text=subset['brand'],\n",
    "            textposition='top center',\n",
    "            name=action,\n",
    "            hovertemplate='<b>%{text}</b><br>Strategic: %{x:.1f}<br>CSR: %{y:.1f}<br>Dealers: %{marker.size}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# 2. Market positioning (dealers vs rating)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=final_analysis['dealer_count'],\n",
    "        y=final_analysis['avg_rating'],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=final_analysis['strategic_value'], \n",
    "                   color=final_analysis['strategic_value'],\n",
    "                   colorscale='Viridis',\n",
    "                   showscale=False),\n",
    "        text=final_analysis['brand_clean'],\n",
    "        textposition='top center',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Performance scores bar chart\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=final_analysis['brand_clean'],\n",
    "        y=final_analysis['strategic_value'],\n",
    "        marker_color=final_analysis['strategic_value'],\n",
    "        marker_colorscale='RdYlGn',\n",
    "        showlegend=False,\n",
    "        text=final_analysis['strategic_value'].round(1),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Recommendations summary\n",
    "rec_counts = recommendations_df['action'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=rec_counts.index,\n",
    "        y=rec_counts.values,\n",
    "        marker_color=[colors.get(action, 'gray') for action in rec_counts.index],\n",
    "        showlegend=False,\n",
    "        text=rec_counts.values,\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title_text=\"Pon Brand Portfolio Analysis - Strategic Recommendations\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Strategic Value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"CSR Score\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Dealer Count\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Avg Rating\", row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Brand\", tickangle=45, row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Strategic Value\", row=2, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Recommendation\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Number of Brands\", row=2, col=2)\n",
    "\n",
    "# Save visualization\n",
    "fig.write_html(OUTPUTS_DIR / 'plots/portfolio_analysis.html')\n",
    "try:\n",
    "    fig.write_image(OUTPUTS_DIR / 'plots/portfolio_analysis.png', width=1200, height=800)\n",
    "    print(\"📊 Portfolio visualization saved as HTML and PNG\")\n",
    "except:\n",
    "    print(\"📊 Portfolio visualization saved as HTML (PNG export failed)\")\n",
    "\n",
    "print(f\"\\n✅ Portfolio Analysis Complete!\")\n",
    "print(f\"   All results exported to: {OUTPUTS_DIR / 'tables'}\")\n",
    "print(f\"   Visualizations saved to: {OUTPUTS_DIR / 'plots'}\")\n",
    "print(f\"\\n🎯 Ready for board presentation with data-driven portfolio strategy!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}