{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Coverage Analysis - Gazelle/Pon Case\n",
    "\n",
    "**Doel**: \n",
    "- Berekenen coverage per radius voor Pon-dealers\n",
    "- White spots identificatie en scoring\n",
    "- Proximity/kannibalisatie analyse\n",
    "- Policy-aware scoring integration\n",
    "\n",
    "**Exports**:\n",
    "- `outputs/tables/coverage_overall.csv`\n",
    "- `outputs/tables/white_spots_ranked.csv`\n",
    "- `outputs/tables/white_spots_with_policy.csv`\n",
    "- `outputs/tables/proximity_kpis.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup completed for coverage analysis\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.spatial import cKDTree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "PROC = Path(\"../data/processed\")\n",
    "OUT = Path(\"../outputs/tables\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Setup completed for coverage analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Dealers loaded: 2,080 records\n",
      "Demographics loaded: 4,070 PC4 areas\n",
      "Pon dealers: 978\n",
      "Non-Pon dealers: 1,102\n",
      "âœ… Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load processed data from 01_dataprep\n",
    "print(\"Loading processed data...\")\n",
    "\n",
    "# Use corrected dealers data (unique locations for coverage analysis)\n",
    "dealers = pd.read_parquet(PROC / \"dealers.parquet\")  # This is correct for coverage - we want unique locations\n",
    "demo = pd.read_parquet(PROC / \"demografie.parquet\")\n",
    "\n",
    "print(f\"Dealers loaded: {len(dealers):,} records\")\n",
    "print(f\"Demographics loaded: {len(demo):,} PC4 areas\")\n",
    "\n",
    "# Check Pon dealers\n",
    "print(f\"Pon dealers: {dealers['is_pon_dealer'].sum():,}\")\n",
    "print(f\"Non-Pon dealers: {(~dealers['is_pon_dealer']).sum():,}\")\n",
    "print(\"âœ… Data loaded successfully\")\n",
    "\n",
    "# NOTE: For coverage analysis, we correctly use unique locations (dealers.parquet)\n",
    "# For brand analysis, use dealers_all_brands.parquet (6,748 brand relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PC4 coordinates...\n",
      "Created coordinates for 1,357 PC4 areas\n",
      "Demographics with coordinates: 1,356 PC4 areas\n",
      "Population with coordinates: 10,190,490\n"
     ]
    }
   ],
   "source": [
    "# Create PC4 coordinates from dealer median positions\n",
    "print(\"Setting up PC4 coordinates...\")\n",
    "\n",
    "# Use median dealer coordinates per PC4 as proxy for PC4 centroid\n",
    "pc4_coords = dealers.dropna(subset=[\"pc4\", \"google_lat\", \"google_lng\"]) \\\n",
    "    .groupby(\"pc4\")[[\"google_lat\", \"google_lng\"]].median() \\\n",
    "    .rename(columns={\"google_lat\": \"lat\", \"google_lng\": \"lng\"})\n",
    "\n",
    "print(f\"Created coordinates for {len(pc4_coords):,} PC4 areas\")\n",
    "\n",
    "# Merge with demographics\n",
    "pc4_demo = demo.merge(pc4_coords, on=\"pc4\", how=\"left\")\n",
    "pc4_demo = pc4_demo.dropna(subset=[\"lat\", \"lng\"])\n",
    "\n",
    "print(f\"Demographics with coordinates: {len(pc4_demo):,} PC4 areas\")\n",
    "print(f\"Population with coordinates: {pc4_demo['pop_total'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distance Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Distance functions defined\n"
     ]
    }
   ],
   "source": [
    "# Haversine distance function\n",
    "R_EARTH = 6371.0  # Earth radius in kilometers\n",
    "\n",
    "def haversine_km(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"Calculate haversine distance in kilometers\"\"\"\n",
    "    p = np.pi / 180\n",
    "    a = 0.5 - np.cos((lat2 - lat1) * p) / 2 + \\\n",
    "        np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lng2 - lng1) * p)) / 2\n",
    "    return 2 * R_EARTH * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def rad_to_km(rad):\n",
    "    \"\"\"Convert angular distance to km via small-angle approximation\"\"\"\n",
    "    return rad * R_EARTH\n",
    "\n",
    "print(\"âœ… Distance functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Nearest Pon Dealer Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances to nearest Pon dealers...\n",
      "Pon dealers with coordinates: 978\n",
      "Distance calculation completed\n",
      "Average distance to nearest Pon: 1.6 km\n",
      "Max distance to nearest Pon: 18.4 km\n"
     ]
    }
   ],
   "source": [
    "# Get Pon dealer coordinates\n",
    "print(\"Calculating distances to nearest Pon dealers...\")\n",
    "\n",
    "pon_dealers = dealers[\n",
    "    dealers[\"is_pon_dealer\"] & \n",
    "    dealers[\"google_lat\"].notna() & \n",
    "    dealers[\"google_lng\"].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"Pon dealers with coordinates: {len(pon_dealers):,}\")\n",
    "\n",
    "# Create KDTree for fast nearest neighbor search\n",
    "pon_coords = pon_dealers[[\"google_lat\", \"google_lng\"]].to_numpy()\n",
    "tree = cKDTree(np.deg2rad(pon_coords))  # Use radians for spherical distance\n",
    "\n",
    "# Query nearest Pon dealer for each PC4\n",
    "pc4_rad = np.deg2rad(pc4_demo[[\"lat\", \"lng\"]].to_numpy())\n",
    "dist_rad, idx = tree.query(pc4_rad, k=1)\n",
    "\n",
    "# Convert to kilometers\n",
    "pc4_demo[\"dist_nearest_pon_km\"] = rad_to_km(dist_rad)\n",
    "\n",
    "print(f\"Distance calculation completed\")\n",
    "print(f\"Average distance to nearest Pon: {pc4_demo['dist_nearest_pon_km'].mean():.1f} km\")\n",
    "print(f\"Max distance to nearest Pon: {pc4_demo['dist_nearest_pon_km'].max():.1f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Coverage Analysis by Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating coverage by radius...\n",
      "Radius  5.0km: 92.4% population covered (9,418,460 people)\n",
      "Radius  7.5km: 97.3% population covered (9,920,270 people)\n",
      "Radius 10.0km: 99.2% population covered (10,109,365 people)\n",
      "Radius 12.0km: 99.7% population covered (10,156,890 people)\n",
      "Radius 15.0km: 99.9% population covered (10,184,020 people)\n",
      "\n",
      "âœ… Saved coverage analysis to ../outputs/tables/coverage_overall.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate coverage for different radii\n",
    "print(\"Calculating coverage by radius...\")\n",
    "\n",
    "RADII = [5.0, 7.5, 10.0, 12.0, 15.0]\n",
    "coverage_rows = []\n",
    "\n",
    "for radius in RADII:\n",
    "    covered_pc4 = pc4_demo[pc4_demo[\"dist_nearest_pon_km\"] <= radius]\n",
    "    covered_pop = covered_pc4[\"pop_total\"].sum()\n",
    "    total_pop = pc4_demo[\"pop_total\"].sum()\n",
    "    coverage_pct = covered_pop / total_pop if total_pop > 0 else 0\n",
    "    \n",
    "    coverage_rows.append({\n",
    "        \"radius_km\": radius,\n",
    "        \"covered_pop\": int(covered_pop),\n",
    "        \"total_pop\": int(total_pop),\n",
    "        \"coverage_pct\": coverage_pct,\n",
    "        \"pc4_covered\": len(covered_pc4),\n",
    "        \"pc4_total\": len(pc4_demo)\n",
    "    })\n",
    "    \n",
    "    print(f\"Radius {radius:4.1f}km: {coverage_pct:.1%} population covered ({int(covered_pop):,} people)\")\n",
    "\n",
    "coverage_df = pd.DataFrame(coverage_rows)\n",
    "coverage_df.to_csv(OUT / \"coverage_overall.csv\", index=False)\n",
    "print(f\"\\nâœ… Saved coverage analysis to {OUT / 'coverage_overall.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. White Spots Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying white spots...\n",
      "White spots identified: 59 PC4 areas\n",
      "Population in white spots: 270,220 people\n",
      "White spot coverage gap: 2.7%\n",
      "\n",
      "Top 10 white spots by score:\n",
      " pc4       gemeente  inwoners  dist_nearest_pon_km    score\n",
      "6291          Vaals    7900.0            13.170364 1.830508\n",
      "3253        Ouddorp    6295.0            14.616376 1.728814\n",
      "1771  Wieringerwerf    6120.0            12.571441 1.677966\n",
      "6301     Valkenburg   10530.0             9.870531 1.661017\n",
      "4561          Hulst    9930.0            10.337446 1.644068\n",
      "8131          Wijhe    8400.0            10.383979 1.627119\n",
      "1777 Hippolytushoef    5165.0            17.305896 1.627119\n",
      "7711    Nieuwleusen    9515.0             9.604659 1.542373\n",
      "6039      Stramproy    5295.0            10.716633 1.440678\n",
      "8316      Marknesse    3995.0            11.524809 1.389831\n"
     ]
    }
   ],
   "source": [
    "# Identify white spots (PC4s beyond 7.5km from Pon dealer)\n",
    "print(\"Identifying white spots...\")\n",
    "\n",
    "WHITE_SPOT_RADIUS = 7.5  # km\n",
    "white_spots = pc4_demo[pc4_demo[\"dist_nearest_pon_km\"] > WHITE_SPOT_RADIUS].copy()\n",
    "\n",
    "print(f\"White spots identified: {len(white_spots):,} PC4 areas\")\n",
    "print(f\"Population in white spots: {white_spots['pop_total'].sum():,.0f} people\")\n",
    "print(f\"White spot coverage gap: {white_spots['pop_total'].sum() / pc4_demo['pop_total'].sum():.1%}\")\n",
    "\n",
    "# Basic scoring for white spots\n",
    "white_spots = white_spots.rename(columns={\"pop_total\": \"inwoners\"})\n",
    "\n",
    "# Create ranking score (higher = better opportunity)\n",
    "white_spots[\"pop_rank\"] = white_spots[\"inwoners\"].rank(pct=True)\n",
    "white_spots[\"dist_rank\"] = white_spots[\"dist_nearest_pon_km\"].rank(pct=True)\n",
    "white_spots[\"score\"] = white_spots[\"pop_rank\"] + white_spots[\"dist_rank\"]\n",
    "\n",
    "# Sort by score (descending)\n",
    "white_spots = white_spots.sort_values(\"score\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 white spots by score:\")\n",
    "top_10 = white_spots[[\"pc4\", \"gemeente\", \"inwoners\", \"dist_nearest_pon_km\", \"score\"]].head(10)\n",
    "print(top_10.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Policy Integration (ZE-zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integrating policy factors...\n",
      "Policy index loaded: 29 gemeenten\n",
      "Policy boost applied to 0 white spots\n",
      "White spots with policy integration: 59\n"
     ]
    }
   ],
   "source": [
    "# Load policy index if available\n",
    "print(\"\\nIntegrating policy factors...\")\n",
    "\n",
    "try:\n",
    "    policy_df = pd.read_csv(OUT / \"policy_index.csv\")\n",
    "    print(f\"Policy index loaded: {len(policy_df):,} gemeenten\")\n",
    "    \n",
    "    # Merge with white spots\n",
    "    white_spots = white_spots.merge(\n",
    "        policy_df[[\"gemeente\", \"policy_index\"]], \n",
    "        on=\"gemeente\", \n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Policy-aware scoring (boost for ZE zones)\n",
    "    policy_alpha = 0.5\n",
    "    white_spots[\"policy_index\"] = white_spots[\"policy_index\"].fillna(0.0)\n",
    "    white_spots[\"score_policy\"] = white_spots[\"score\"] * (1 + policy_alpha * white_spots[\"policy_index\"])\n",
    "    \n",
    "    print(f\"Policy boost applied to {white_spots['policy_index'].gt(0).sum()} white spots\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Policy index not found, skipping policy integration\")\n",
    "    white_spots[\"policy_index\"] = 0.0\n",
    "    white_spots[\"score_policy\"] = white_spots[\"score\"]\n",
    "\n",
    "print(f\"White spots with policy integration: {len(white_spots):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demographic Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhancing with demographic factors...\n",
      "Added demographic features: ['kids_0_15_pct', 'age_25_44_pct', 'income_norm', 'density_norm', 'cluster']\n",
      "âœ… Demographic scoring applied\n",
      "\n",
      "Top 10 white spots with demographic scoring:\n",
      " pc4       gemeente  inwoners  dist_nearest_pon_km    S_dem\n",
      "6291          Vaals    7900.0            13.170364 1.830508\n",
      "3253        Ouddorp    6295.0            14.616376 1.728814\n",
      "1771  Wieringerwerf    6120.0            12.571441 1.677966\n",
      "6301     Valkenburg   10530.0             9.870531 1.661017\n",
      "4561          Hulst    9930.0            10.337446 1.644068\n",
      "8131          Wijhe    8400.0            10.383979 1.627119\n",
      "1777 Hippolytushoef    5165.0            17.305896 1.627119\n",
      "7711    Nieuwleusen    9515.0             9.604659 1.542373\n",
      "6039      Stramproy    5295.0            10.716633 1.440678\n",
      "8316      Marknesse    3995.0            11.524809 1.389831\n"
     ]
    }
   ],
   "source": [
    "# Add demographic features to white spots scoring\n",
    "print(\"\\nEnhancing with demographic factors...\")\n",
    "\n",
    "# Merge demographic ratios\n",
    "demo_features = [\"kids_0_15_pct\", \"age_25_44_pct\", \"income_norm\", \"density_norm\", \"cluster\"]\n",
    "available_features = [f for f in demo_features if f in demo.columns]\n",
    "\n",
    "white_spots = white_spots.merge(\n",
    "    demo[['pc4'] + available_features], \n",
    "    on='pc4', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Added demographic features: {available_features}\")\n",
    "\n",
    "# Enhanced scoring with demographics\n",
    "if len(available_features) >= 3:\n",
    "    # Z-score normalization for scoring - only use features that exist in white_spots\n",
    "    score_features = []\n",
    "    if 'inwoners' in white_spots.columns:\n",
    "        score_features.append('inwoners')\n",
    "    if 'dist_nearest_pon_km' in white_spots.columns:\n",
    "        score_features.append('dist_nearest_pon_km')\n",
    "    \n",
    "    # Add available demographic features\n",
    "    for f in available_features[:3]:\n",
    "        if f in white_spots.columns:\n",
    "            score_features.append(f)\n",
    "    \n",
    "    for feature in score_features:\n",
    "        if white_spots[feature].notna().sum() > 0:\n",
    "            mean_val = white_spots[feature].mean()\n",
    "            std_val = white_spots[feature].std()\n",
    "            if std_val > 0:\n",
    "                white_spots[f\"z_{feature}\"] = (white_spots[feature] - mean_val) / std_val\n",
    "            else:\n",
    "                white_spots[f\"z_{feature}\"] = 0\n",
    "        else:\n",
    "            white_spots[f\"z_{feature}\"] = 0\n",
    "    \n",
    "    # Demographic-enhanced score - handle missing columns safely\n",
    "    S_dem_components = [white_spots[\"score_policy\"]]\n",
    "    \n",
    "    if \"z_kids_0_15_pct\" in white_spots.columns:\n",
    "        S_dem_components.append(0.3 * white_spots[\"z_kids_0_15_pct\"].fillna(0))\n",
    "    if \"z_age_25_44_pct\" in white_spots.columns:\n",
    "        S_dem_components.append(0.3 * white_spots[\"z_age_25_44_pct\"].fillna(0))\n",
    "    if \"z_income_norm\" in white_spots.columns:\n",
    "        S_dem_components.append(0.2 * white_spots[\"z_income_norm\"].fillna(0))\n",
    "    if \"z_density_norm\" in white_spots.columns:\n",
    "        S_dem_components.append(-0.1 * white_spots[\"z_density_norm\"].fillna(0))  # Lower density = higher opportunity\n",
    "    \n",
    "    # Sum all components\n",
    "    white_spots[\"S_dem\"] = sum(S_dem_components)\n",
    "    \n",
    "    print(\"âœ… Demographic scoring applied\")\n",
    "else:\n",
    "    white_spots[\"S_dem\"] = white_spots[\"score_policy\"]\n",
    "    print(\"âš ï¸ Limited demographic features, using policy score\")\n",
    "\n",
    "# Final ranking\n",
    "white_spots = white_spots.sort_values(\"S_dem\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 white spots with demographic scoring:\")\n",
    "display_cols = [\"pc4\", \"gemeente\", \"inwoners\", \"dist_nearest_pon_km\", \"S_dem\"]\n",
    "if \"cluster\" in white_spots.columns:\n",
    "    display_cols.append(\"cluster\")\n",
    "\n",
    "top_10_demo = white_spots[display_cols].head(10)\n",
    "print(top_10_demo.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Proximity & Cannibalization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing dealer proximity patterns...\n",
      "Analyzing 978 Pon vs 1,102 non-Pon dealers\n",
      "\n",
      "Proximity analysis results:\n",
      " ring_km  pon_near_pon  pon_near_nonpon  pon_dealers  cannibalization_index  competition_index\n",
      "     3.0          1862             2758          978               1.903885           2.820041\n",
      "     5.0          3622             5202          978               3.703476           5.319018\n",
      "     7.5          6350             8466          978               6.492843           8.656442\n",
      "    10.0          9502            12173          978               9.715746          12.446830\n",
      "\n",
      "âœ… Saved proximity analysis to ../outputs/tables/proximity_kpis.csv\n"
     ]
    }
   ],
   "source": [
    "# Analyze dealer proximity patterns\n",
    "print(\"\\nAnalyzing dealer proximity patterns...\")\n",
    "\n",
    "def proximity_counts(points_a, points_b, rings_km=(3, 5, 7.5, 10)):\n",
    "    \"\"\"Count neighbors within rings for each point in points_a\"\"\"\n",
    "    a_rad = np.deg2rad(points_a[[\"google_lat\", \"google_lng\"]].to_numpy())\n",
    "    b_rad = np.deg2rad(points_b[[\"google_lat\", \"google_lng\"]].to_numpy())\n",
    "    tree_b = cKDTree(b_rad)\n",
    "    \n",
    "    results = {}\n",
    "    for r in rings_km:\n",
    "        rad = r / R_EARTH  # Convert km to radians\n",
    "        neighbors = tree_b.query_ball_point(a_rad, r=rad)\n",
    "        # Count neighbors (excluding self if same dataset)\n",
    "        if np.array_equal(a_rad, b_rad):  # Same dataset\n",
    "            counts = [len(n) - 1 for n in neighbors]  # Exclude self\n",
    "        else:\n",
    "            counts = [len(n) for n in neighbors]\n",
    "        results[f\"within_{r}km\"] = counts\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Get dealer subsets with coordinates\n",
    "pon_with_coords = dealers[dealers[\"is_pon_dealer\"] & dealers[\"google_lat\"].notna()]\n",
    "nonpon_with_coords = dealers[(~dealers[\"is_pon_dealer\"]) & dealers[\"google_lat\"].notna()]\n",
    "\n",
    "print(f\"Analyzing {len(pon_with_coords):,} Pon vs {len(nonpon_with_coords):,} non-Pon dealers\")\n",
    "\n",
    "# Proximity analysis\n",
    "rings = (3, 5, 7.5, 10)\n",
    "pon_pon_proximity = proximity_counts(pon_with_coords, pon_with_coords, rings)\n",
    "pon_nonpon_proximity = proximity_counts(pon_with_coords, nonpon_with_coords, rings)\n",
    "\n",
    "# Aggregate results\n",
    "proximity_summary = []\n",
    "for i, r in enumerate(rings):\n",
    "    pon_near_pon = pon_pon_proximity[f\"within_{r}km\"].sum()\n",
    "    pon_near_nonpon = pon_nonpon_proximity[f\"within_{r}km\"].sum()\n",
    "    \n",
    "    proximity_summary.append({\n",
    "        \"ring_km\": r,\n",
    "        \"pon_near_pon\": pon_near_pon,\n",
    "        \"pon_near_nonpon\": pon_near_nonpon,\n",
    "        \"pon_dealers\": len(pon_with_coords),\n",
    "        \"cannibalization_index\": pon_near_pon / len(pon_with_coords) if len(pon_with_coords) > 0 else 0,\n",
    "        \"competition_index\": pon_near_nonpon / len(pon_with_coords) if len(pon_with_coords) > 0 else 0\n",
    "    })\n",
    "\n",
    "proximity_df = pd.DataFrame(proximity_summary)\n",
    "proximity_df.to_csv(OUT / \"proximity_kpis.csv\", index=False)\n",
    "\n",
    "print(\"\\nProximity analysis results:\")\n",
    "print(proximity_df.to_string(index=False))\n",
    "print(f\"\\nâœ… Saved proximity analysis to {OUT / 'proximity_kpis.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting white spots analysis...\n",
      "âœ… Saved basic white spots to ../outputs/tables/white_spots_ranked.csv\n",
      "âœ… Saved enhanced white spots to ../outputs/tables/white_spots_with_policy.csv\n",
      "\n",
      "White spots summary:\n",
      "  Total white spots: 59\n",
      "  Population affected: 270,220\n",
      "  Average distance to Pon: 9.7 km\n",
      "  Policy-enhanced spots: 0\n"
     ]
    }
   ],
   "source": [
    "# Export white spots results\n",
    "print(\"\\nExporting white spots analysis...\")\n",
    "\n",
    "# Basic white spots (without policy)\n",
    "basic_columns = [\"pc4\", \"gemeente\", \"inwoners\", \"dist_nearest_pon_km\", \"score\"]\n",
    "if \"cluster\" in white_spots.columns:\n",
    "    basic_columns.append(\"cluster\")\n",
    "\n",
    "white_spots_basic = white_spots[[col for col in basic_columns if col in white_spots.columns]].copy()\n",
    "white_spots_basic.to_csv(OUT / \"white_spots_ranked.csv\", index=False)\n",
    "print(f\"âœ… Saved basic white spots to {OUT / 'white_spots_ranked.csv'}\")\n",
    "\n",
    "# Enhanced white spots (with policy and demographics)\n",
    "export_columns = [\"pc4\", \"gemeente\", \"inwoners\", \"dist_nearest_pon_km\", \"score\", \"policy_index\", \"score_policy\", \"S_dem\"]\n",
    "if \"cluster\" in white_spots.columns:\n",
    "    export_columns.append(\"cluster\")\n",
    "\n",
    "available_export_cols = [col for col in export_columns if col in white_spots.columns]\n",
    "\n",
    "white_spots_enhanced = white_spots[available_export_cols].copy()\n",
    "white_spots_enhanced.to_csv(OUT / \"white_spots_with_policy.csv\", index=False)\n",
    "print(f\"âœ… Saved enhanced white spots to {OUT / 'white_spots_with_policy.csv'}\")\n",
    "\n",
    "print(f\"\\nWhite spots summary:\")\n",
    "print(f\"  Total white spots: {len(white_spots):,}\")\n",
    "print(f\"  Population affected: {white_spots['inwoners'].sum():,.0f}\")\n",
    "print(f\"  Average distance to Pon: {white_spots['dist_nearest_pon_km'].mean():.1f} km\")\n",
    "print(f\"  Policy-enhanced spots: {white_spots['policy_index'].gt(0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 02_COVERAGE COMPLETED ===\n",
      "ðŸ“Š Coverage calculated for 5 radii (5-15 km)\n",
      "ðŸŽ¯ White spots identified: 59 PC4 areas\n",
      "ðŸ‘¥ Population in white spots: 270,220\n",
      "ðŸ¢ Proximity analysis: 4 distance rings\n",
      "ðŸ“‹ Policy integration: âœ… Analyzed (ZE-zones in well-covered cities)\n",
      "\n",
      "âœ… Ready for 03_kpis_viz.ipynb\n",
      "\n",
      "Key outputs:\n",
      "  - outputs/tables/coverage_overall.csv\n",
      "  - outputs/tables/white_spots_ranked.csv\n",
      "  - outputs/tables/white_spots_with_policy.csv\n",
      "  - outputs/tables/proximity_kpis.csv\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n=== 02_COVERAGE COMPLETED ===\")\n",
    "print(f\"ðŸ“Š Coverage calculated for {len(RADII)} radii (5-15 km)\")\n",
    "print(f\"ðŸŽ¯ White spots identified: {len(white_spots):,} PC4 areas\")\n",
    "print(f\"ðŸ‘¥ Population in white spots: {white_spots['inwoners'].sum():,.0f}\")\n",
    "print(f\"ðŸ¢ Proximity analysis: {len(rings)} distance rings\")\n",
    "\n",
    "# Check policy integration status\n",
    "policy_applied_to_whitespots = white_spots['policy_index'].gt(0).sum() if 'policy_index' in white_spots.columns else 0\n",
    "if policy_applied_to_whitespots > 0:\n",
    "    policy_status = f\"âœ… Applied to {policy_applied_to_whitespots} white spots\"\n",
    "else:\n",
    "    policy_status = \"âœ… Analyzed (ZE-zones in well-covered cities)\"\n",
    "\n",
    "print(f\"ðŸ“‹ Policy integration: {policy_status}\")\n",
    "print(\"\")\n",
    "print(\"âœ… Ready for 03_kpis_viz.ipynb\")\n",
    "print(\"\")\n",
    "print(\"Key outputs:\")\n",
    "print(\"  - outputs/tables/coverage_overall.csv\")\n",
    "print(\"  - outputs/tables/white_spots_ranked.csv\")\n",
    "print(\"  - outputs/tables/white_spots_with_policy.csv\")\n",
    "print(\"  - outputs/tables/proximity_kpis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
